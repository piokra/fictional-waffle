% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[10pt]{article} % use larger type; default would be 10pt
\linespread{1.3}
\usepackage{polski}
\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage[letterpaper, portrait, margin=2.5cm]{geometry}

%\usepackage{helvet}
\usepackage{indentfirst}
%\renewcommand{\familydefault}{\sfdefault}
%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{svg}
\usepackage{amsthm}
\usepackage{ bbold }
\usepackage{eufrak}

%\usepackage{braket}
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}
	
%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% Math ops %%%
\DeclareMathOperator{\Trs}{Tr}
\DeclareMathOperator{\Rank}{rank}

%%% END

%%% Extra commands %%%
\newcommand{\Mats}[1]{\mathcal{L}(#1)}
\newcommand{\Hx}[1]{\mathcal{H}^{#1}}
\newcommand{\LHx}[1]{\Mats{\Hx{#1}}}
\newcommand{\HAi}{\Hx{A_1}}
\newcommand{\LHAi}{\Mats{\HAi}}
\newcommand{\MXi}[3]{\mathcal{M}^{#1}_{#2}(#3)}
\newcommand{\MXin}[2]{\mathcal{M}^{#1}_{#2}}
\newcommand{\MAin}[0]{\MXin{A}{i}}
\newcommand{\MAi}[1]{\MXi{A}{i}{#1}}
\newcommand{\MAir}{\MAi{\rho}}
\newcommand{\Idx}[1]{\mathbb{1}^{#1}}
\newcommand{\Tr}[1]{\Trs(#1)}
\newcommand{\Pro}[1]{\Pr(#1)}
\newcommand{\Prt}[2]{\Pr(#1, #2)}
\newcommand{\Ket}[1]{|#1\rangle}
\newcommand{\Bra}[1]{\langle#1|}
\newcommand{\BBra}[1]{\langle\langle#1|}
\newcommand{\KKet}[1]{|#1\rangle\rangle}
\newcommand{\Braket}[1]{\langle#1\rangle}
\newcommand{\CP}{\textit{completely positive}}
\newcommand{\TP}{\textit{trace preserving}}
\newcommand{\CPTP}{\textit{completely posite trace preserving}}
\newcommand{\WAll}{W^{A_1A_2B_1B_2}}
\newcommand{\MA}{M^{A_1A_2}}
\newcommand{\MB}{M^{B_1B_2}}
\newcommand{\mai}[1]{\MA_{#1}}
\newcommand{\mbi}[1]{\MB_{#1}}
\newcommand{\KP}{\Ket{\psi}}
\newcommand{\BP}{\Bra{\psi}}
\newcommand{\X}{\mathbb{X}}
\newcommand{\Y}{\mathbb{Y}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{1}}
\newcommand{\IO}{\mathbb{1}^\circ}
\newcommand{\MCJ}{\mathfrak{C}}
\newcommand{\LV}{L_V}
\newcommand{\LPV}{{L^\perp_V}}
%%% END

%%% The "real" document content comes below...

\title{Przyczynowe więzy na strukturę korelacji w formalizmie kwantowym}
\author{Piotr Krasuń}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 
\setlength{\parindent}{1.25cm}
\begin{document}
\maketitle

\newpage
%\begin{multicols*}{2}
\begin{abstract}
W pracy został zaprezentowany formalizm macierzy procesu, który opisuje regułę obliczania prawdopodobieństw otrzymania danych wyników w lokalnych laboratoriach przy wykorzystaniu potencjalnie nieprzyczynowych zasobów. Następnie przedstawiono zadanie komunikacyjne, w którym zasób o nieokreślonej przyczynowości może osiągać lepsze wyniki niż zasób klasyczny. Dalej zaprezentowano tak zwany \textit{causal witness}, który służy do stwierdzenia, czy dany zasób można rozłożyć na probabilistyczną kombinację zasobów o ściśle określonej przyczynowości. Na ich podstawie wykonano eksperymenty, które empirycznie potwierdziły fakt, że nieprzycznowość występuje w naturze. Następnie przedstawiono postulat, który ma wskazywać jakie procesy mogą być implementowalne fizycznie.
\end{abstract}
%\addto{\captionsLANGUAGE}{\renewcommand{\abstractname}{Abstract}}
\renewcommand{\abstractname}{Abstract}
\begin{abstract}
In this work process matrix formalism is presented. It can be considered a way to calculate probabilities of obtaining certain results in local laboratories using possibly not casual resources. Next a communication task is shown. In this task a resource that is not casual can do better than a classic one. Following it a tool that can discriminate processes with indefinite casual order is described. The so called causal witness was used to experimentally show that indefinite causal order is, in fact, a naturally occuring phenomena. Following it a purification postulate is characterized. It is a tool that is theorized to imply whether a following resource may be implemented physically.
\end{abstract}
\section{Wstęp}
%%%%
\subsection{Historia}
Mechanika kwantowa od samego początku jej badania budziła wiele kontrowersji. Wiele osób miało problem z zaakceptowaniem faktu, iż
na fundamentalnym poziomie rzeczywistość nie jest deterministyczna, jak nam się wydawało. Zarówno losowa natura tej teorii, jak i wiele "dziwnych" cech mechaniki kwantowej była początkowo trudna do zaakceptowania. Rok po opublikowaniu pracy Schrödingera, Einstein w swojej pracy zamieścił zdanie, które kierunkowało badania w tamtym czasie, zaś dziś jest wraz z innymi popularnymi "powiedzonkami" kwantowymi zakorzenione w kulturze, a mianowicie, że "Bóg nie gra w kości". Ta teza później okazała się być nieprawdziwa - przynajmniej nie w takim stopniu, w jakim autor by sobie życzył. Sam formalizm doczekał się wielu interpretacji, często bardziej filozoficznych. Dzisiaj najpopularniejszymi są interpretacja kopenhaska, teoria wielu światów, czy idei inkorporująca kwantową grawitację w mechanizmie pomiaru. Mimo tego jest to bardzo matematycznie elegancka teoria, którą można nazwać jednym z największych osiągnięć współczesnej fizyki. Wielokrotnie jej "dziwne" przewidywania zostały potwierdzone eksperymentalnie z wręcz idealną dokładnością (w przeciwieństwie do np. stałej kosmologicznej, której niedokładność przekracza wiele dziesiątek rzędów wielkości). 
\subsection{Podstawowe informacje}
Przechodząc do bardziej konkretnych rzeczy, systemy w mechanice kwantowej opisuje się jako elementy przestrzeni Hilberta $\psi \in \Hx{}$, a tak zwane obserwable - samosprzężone operatory $A \in \LHx{}$, które opisują pomiary, jakie można wykonać na danym systemie. W przypadku skończenie wymiarowym bądź policzalnym można powiedzieć, że $\Hx{A} = \mathcal{C}^N$ i
obserwable są po prostu macierzami hermitowskimi odpowiedniego wymiaru. Przez znak równości rozumie się przestrzeń Hilberta zbudowaną na tym zbiorze z odpowiednimi działaniami. Dosyć standardowym i wygodnym jest wykorzystywanie tak zwanej notacji Diraca, a mianowicie przedstawianie $\psi = \Ket{\psi}$ i $\psi^\dag = \Bra{\psi}$
\begin{align}
\psi = 
\begin{pmatrix}
a_1\\a_2\\a_3
\end{pmatrix}
:= \Ket{\psi}
\quad & \quad\psi^\dag = 
\begin{pmatrix}
a_1^*~a_2^*~a_3^*
\end{pmatrix}
:= \Bra{\psi}
\end{align}
\begin{figure}[th]
\centering
\includegraphics[width=0.20\textwidth]{obrazki/Bloch_sphere}
\caption{Sfera Blocha. Punkty na tej sferze opisują wszystkie możliwe stany $\KP$.}
\label{fig:bloch}
\end{figure}
Wygodnie narzucić warunek normalizacji stanów, a mianowicie $\Bra{\psi}\Ket{\psi} := \Braket{\psi|\psi} = 1$, wtedy wartość oczekiwaną obserwabli w danym stanie $\Ket{\psi}$ oblicza się tak: $\Braket{A} := \Bra{\psi}A\Ket{\psi}$. Warto zauważyć, że skoro obserwable opisywane są przez macierze hermitowskie, można 
skorzystać z twierdzenia spektralnego i zapisać $A = \sum_i^N \lambda_i \Ket{\lambda_i}$, gdzie $\lambda_i$ opisuje i-tą wartość własną zaś $\Ket{\lambda_i}$ to i-ty wektor własny, który dobrano tak, że $\Braket{i|j} = \delta_{ij}$, $\{\Ket{i}\}$ tworzy ortonormalna bazę w $\Hx{}$. Jednym z postulatów mechaniki kwantowej jest tzw. postulat pomiaru von Neumanna. Mówi on, że wykonując pomiar obserwablą A na systemie w stanie $\Ket{\psi}$ i otrzymując wartość $\lambda_i$ odpowiadająca wektorowi własnemu $\Ket{\lamdbda_i}$ zapada się on w stan $\Ket{\lambda_i}$. Można zapisać go w następujący sposób opisujący warunkową ewolucję po pomiarze
\begin{equation}
\label{eq:cond_ev}
\Ket{\psi} \mapsto \frac{\Pi_i\Ket{\psi}}{\sqrt{\Bra{\psi}\Pi_i \Ket{\psi}}},
\end{equation}
gdzie $\Pi_i$ jest projektorem odpowiadającym $\Ket{\lambda_i}\Bra{\lambda_i}$. Zapisująć $\KP = \sum^N_i a_i \Ket{\lambda_i}, \sum^N_i |a_i|^2=1$, prawdopodobieństwo zaobserwowania wyniku $\lambda_i$ jest równe $|a_i|^2$, lub równoważnie
\begin{equation}
\Pro{\lambda_i} = \BP \Pi_i \KP,
\end{equation}
co znane jest jako reguła Borna. Fakt, że obserwable są opisywane przez macierze Hermitowskie zapewnia, że $\sum^N_i \Ket{\lambda_i}\Bra{\lambda_i} = \mathbb{1}$, co dalej implikuje, że $\sum^N_i \Pro{\lambda_i} = \sum^N_i \BP \Pi_i \KP = \BP \sum^N_i \Pi_i \KP = \Braket{\psi | \psi} = 1$
Stan całego systemu składającego się z pewnej ilości systemów opisuje element z
\begin{equation}
\Hx{AB\dots} = \Hx{A} \otimes \Hx{B} \otimes \dots,
\end{equation}
gdzie $\otimes$ to iloczyn tensorowy. Wraz ze wzrostem systemów składających się na system ilość wektorów bazowych rośnie eksponencjalnie, co jest fundamentem tzw. "kwantowego przyśpieszenia", które pozwala heurystycznie/przybliżenie rozwiązać na komputerach kwantowych niektóre klasyczne problemy z eksponencjalnym przyśpieszeniem,
np. faktoryzacja liczb, rozwiązywanie układów liniowych czy odpowiednio sformułowane problemy uczenia maszynowego.
Ważną rzeczą do zaobserwowania jest fakt, że istnieją takie systemy, których nie można zapisać jako iloczyn stanów w poszczególnych podsystemach. Klasycznym przykładem tego jest
\begin{gather*}
\Hx{AB} = \mathcal{C}^2 \otimes \mathcal{C}^2 \\
\KP = \Ket{1}_A \otimes \Ket{1}_B + \Ket{0}_A \otimes \Ket{0}_B := \Ket{1}\Ket{1} + \Ket{0}\Ket{0} := \Ket{11} + \Ket{00} \\
a_0\Ket{0} + a_1\Ket{1} \otimes b_0\Ket{0} + b_1\Ket{1} = a_0b_0 \Ket{00} + a_0b_1\Ket{01} + a_1b_0\Ket{10} + a_1b_1\Ket{11} \\
a_0b_1 = 0\implies a_0 = 0\vee b_1 = 0 \\
a_1b_0 = 0\implies a_1 = 0\vee b_0 = 0 \\
\text{Powyższe implikuje, że } a_0b_0 \neg 1 \vee a_1b_1 \neg 1.
\end{gather*} Takie systemy, których nie da się zapisać w postaci $\Ket{\Psi} = \Ket{\psi}_A \otimes \Ket{\phi}_B$, nazywa się splątanymi. Splątanie kwantowe jest zasobem, który znalazł zastosowanie w wielu nowatorskich aplikacjach, jak np. kryptografia kwantowa, certyfikowana losowość, teleportacja kwantowa czy wcześniej przytoczone "kwantowe przyśpieszenie".
Często w rozważaniach ogranicza się do skończonych przestrzeni Hilberta o wybranych rozmiarach. Najmniejszą i niepodzielną jednostką informacji jest kubit ($\Hx{} = \mathcal{C}^2$), fizycznie reprezentujący np. cząstkę ze spinem-$\frac{1}{2}$ (elektron), polaryzację fotonu. W wielu dziedzinach informatyki kwantowej ogranicza się praktycznie wyłącznie do analizy systemów złożonych z kubitów ze względu
na pewną prostotę i wygodę badania takich systemów. Ciekawą interpretacją kubitów prezentuje Sfera Blocha (\ref{rys. fig:bloch}). Punkty na tej sferze opisują wszystkie prawidłowe znormalizowane $\KP \in \mathcal{C}^2$.
Okazuje się jednak, że formalizm stanów jest niewystarczający do opisu zespołów statystycznych (system znajduje się w jakimś z $\Ket{\psi_i}$ stanów z prawdopodobieństwem $p_i$) wynikających z braku pełnej wiedzy o systemie bądź sposobie jego przygotowania. Do opisu takich sytuacji używa się macierzy gęstości, definiowanych następująco
\begin{gather}
\rho = \KP \BP \\
\Braket{A} = \Tr{A\rho} \\
\Pro{\lambda_i} = \Tr{\Pi_i \rho}\\
\rho \mapsto \frac{\Pi_i\rho\Pi_i}{\Trs(\Pi_i\rho)}
\end{gather}
Prócz warunkowej ewolucji podczas pomiaru, systemy kwantowe podlegają również ewolucji czasowej. W obrazie Schrödingera ewoluują stany. Wygląda to następująco
\begin{gather}
U(t)\Ket{\psi(0)} = \Ket{\psi(t)} \\
U(t)^\dag\Ket{\psi(t)} = \Ket{\psi(0)}
\end{gather}
W obrazie Heisenberga ewoluują zaś obserwable
\begin{gather}
A(t) = U^\dag A(0)U,
\end{gather}
gdzie $U(t)$ jest pewnym unitarnym operatorem ($U^\dag U = \mathbb{1}$) działającym na $\Hx{}$. Pomiar rzutujący nie jest jedynym pomiarem, który można wykonać. Najogólniejszym pomiarem, który można wykonać w mechanice kwantowej jest \textit{positive valued measurement} (POVM). Opisywany jest on przez
zbiór takich operatorów $\{E_i\}$, że $E_i > 0,~\sum_i E_i = \mathbb{1}$. Poprzednie reguły przechodzą w
\begin{gather}
\Pro{x_i} = \Bra{\psi} E_i \Ket{\psi}\\
\Pro{x_i} = \Tr{E_i \rho} \\
E_i = \sum_j = A^\dag_{ij}A_{ij} \\ 
\rho \mapsto \frac{\sum_j A_{ij} \rho A^\dag_{ij}}{\Tr{\sum_j A_{ij} \rho A^\dag_{ij}}}.
\end{gather} Pomiary takie realizuje się korzystając z \textit{ancilli} (pomocniczy system), ewoluując złożony system odpowiednio dobranym operatorem unitarnym, następnie dokonując pomiaru rzutującego na \textit{ancilli} i po odnotowaniu wyniku odrzuceniu jej.
% tutaj moze przyklad
Ważnym narzędziem w formalizmie kwantowym są tak zwane kanały kwantowe \textit{quantum channel}, opisujące fizyczne połączenia, ich działania na fizyczny system. Klasycznym analogiem może być np. linia telefoniczna czy światłowód transmitujący internet. 
Przykładem fizycznej implementacji może znów być światłowód, który transmituje fotony, opisywany jako kubit. 
Kanały kwantowe opisują mapy $\mathcal{M}: \mathcal{L}(\Hx{A}) \to \mathcal{L}{\Hx{B}}$ mapujące liniowe operatory w przestrzeni wejściowej na liniowe operatory w przestrzeni wyjściowej, gdzie $\mathcal{M}$ jest \textit{completely positive} (CP)\footnote
{
Mapę $\phi: A \to B$ nazywa się nieujemną, gdy $\phi(a) \geq 0 \forall a\geq 0 \in A$. Nazywa się ją CP, gdy $\phi \otimes \mathcal{I}_n$ również jest nieujemna $\forall n \in \mathcal{N}$.
}, $\mathcal{M}(\mathbb{1}) = \mathbb{1}$. Najogólniej kanały idealne, czyli takie, z których możemy otrzymać pełną informację o przychodzącym systemie, opisuje się $\mathcal{M}(\rho) = U^* \rho U$, gdzie U jest pewną macierzą unitarną. W rzeczywistych sytuacjach jednakże nie da się uniknąć
oddziaływania z otoczeniem, który posiada dodatkowe niemierzalne stopnie swobody. Takie zaszumione kanały opisuje ogólnie $\mathcal{M}(\rho) = \Trs_{otoczenie}(U* \rho \otimes \rho_0 U)$, gdzie $\Trs_{otoczenie}$ opisuje operację śladu częściowego po stopniach swobody otoczenia, zaś operator unitarny U
opisuje ewolucję czasową systemu i otoczenia, a $\rho_0$ jest stanem początkowym otoczenia \cite{fund}. Jasnym jest, że posiadając wyłącznie wiedzę na temat systemu $\rho$ nie jest możliwe w ogólności odtworzenie informacji wysłanych.
Typowym przykładem takiego zaszumionego kanału może być kanał depolaryzujący, który z prawdopodobieństwem $\eta$ idealnie transmituje system, zaś z prawdopodobieństwem $1-\eta$ depolaryzuje system, $\mathcal{M}(\rho) = \eta\rho+(1-\rho)\I$. Najogólniejszym modelem kanałów kwantowych jest tzw.
\textit{quantum channel with memory} (kwantowy kanał z pamięcią) opisany np. w \cite{memory}.

%%%%
\section{Macierz Procesu}
\label{macierz_procesu}
Jednym z podejść do eksploracji korelacji nie zachowujących przyczynowego porządku jest rozwinięty w \cite{process_matrix} formalizm macierzy procesu.
Ewidentną zaletą tego podejścia jest zgodność z mechanika kwantową na poziomie lokalnych eksperymentów. Jest to niejakie rozszerzenie i enkapsulacja idei POVM i reguły Borna. Podejście to porzuca założenie globalnej struktury czasoprzestrzeni. W celu zachowania zgodności z mechaniką kwantową na poziomie lokalnym opiera się na następującym założeniu: operacje wykonywane przez poszczególną stronę są opisywane przez mechanikę kwantową w standardowym przyczynowym sformułowaniu, które można opisywać przy pomocy zbioru \textit{quantum instruments} \cite{quantum_instrument} z wejściową przestrzenią Hilberta $\mathcal{H}^{A_1}$ i przestrzenią wyjściową  $\mathcal{H}^{A_2}$. Najogólniej można je realizować poprzez zadziałanie unitarną transformacją na system wejściowy i \textit{ancilla}, następnie wykonanie rzutującego pomiaru na części systemu pozostawiając pozostała część systemu jako wyjście. Alicja wykorzystując dany instrument otrzymuje jeden z możliwych wyników $x_i$, który indukuje transformację $\mathcal{M}^A_i$ z wejścia na wyjście. Transformacja ta odpowiada \CP~(CP) mapie
\begin{equation}
\mathcal{M}^A_i : \mathcal{L}(\mathcal{H}^{A_1}) \mapsto \mathcal{L}(\mathcal{H}^{A_2}),
\end{equation}
gdzie $\LHx{X}$ jest przestrzenią macierzy na $\Hx{X}$, której wymiar to $d_X$. Jej działanie na macierz gęstości $\rho$ opisuje następująca formuła:
\begin{equation}
\label{yolo}
\MAi{\rho} = \sum^m_{j=1} E_{ij} ^\dag \rho E_{ij},
\end{equation}
gdzie macierze $E_{ij}$ spełniają następujące własności:
\begin{gather}
\label{eq:id_proj0} 
\sum^m_{j=0} E_{ij}^\dag E_{ij} \leq \Idx{A_1} \\
\label{eq:id_proj} 
\sum^n_{i=0} \sum^m_{j=0} E_{ij}^\dag E_{ij} = \Idx{A_1}
\end{gather}
Takie mapy, które spełniają \eqref{eq:id_proj0} z równością, nazywa się \TP (TP).
Prawdopodobieństwo zaobserwowania wyniku realizowanego przez mapę $\MAin$ to
\begin{equation}
\Pro{\MAin} = \Tr{\MAir}
\end{equation}
Widać od razu, że równanie \eqref{eq:id_proj} narzuca, by możliwość zaobserwowania dowolnego wyniku była równa 1.
W przypadku, gdy mamy do czynienia z więcej niż jedną stroną, \textit{procesem} będziemy nazywać listę $\Pr(\MXin{A}{i}, \MXin{B}{j}, \dots)$ dla wszystkich możliwych lokalnych wyników. Dalej w tym rozdziale będzie opisywany wyłącznie przypadek dwustronny, jednakże rozszerzenie formalizmu na przypadek wielostronny jest trywialny. Wygodnym sposobem przedstawiania map $\MAin$ jest izomorfizm Choi-Jamiołkowsky (CJ) \cite{cj_iso1, cj_iso2}, który pozwala przedstawiać transformacje liniowe przy pomocy macierzy. Macierz CJ $M^{A_1A_2}_i \in \Mats{\Hx{A_1} \otimes \Hx{A_2}} \geq 0$ jest zdefiniowana jako
\begin{gather}
\label{eq:cj_iso}
\MCJ (\mathcal{M}) = M^{A_1A_2}_i := [\mathcal{I} \otimes \MAi{ \KKet{\I} \BBra{\I}}]^T= \left[\sum^{d_{A_1}-1}_{i,j=0} \Ket{i}\Bra{j} \otimes \mathcal{M}(\Ket{i}\Bra{j})\right]^T, \\
\KKet{\I} = \sum^{d_{A_1}-1}_{i=0} \Ket{ii},
\end{gather}
gdzie $\{\Ket{j}\}^{d_{A_1}}$ tworzy ortonormalna bazę w $\HAi$. 
Często wygodnie korzystać z odpowiednika \eqref{eq:id_proj0} i \eqref{eq:id_proj} dla postaci CJ map, który wygląda następująco:
\begin{gather}
\Trs_{A_2} \left[ M^{A_1A_2}_i \right] \leq \I^{A_1},~\forall i\\ 
\sum_i \Trs_{A_2} \left[ M^{A_1A_2}_i \right] = \I^{A_1}
\end{gather}
Drugi izomorfizm CJ pozwala przedstawiać macierze przy pomocy wektorów, tzw. "podwójnych ketów",
\begin{equation}
\KKet{A} := \I \otimes A\KKet{\I} = \sum^{d_{A_1}-1}_{i=0} \Ket{i} A \Ket{i}
\end{equation}
Korzystając z tego przejścia można zapisać prawdopodobieństwo dwóch rezultatów jako 
\begin{equation}
\label{eq:cj_prob}
\Prt{\MAin}{\MXin{B}{j}} = \Tr{\WAll(M^{A_1A_2}_i \otimes M^{B_1B_2}_j)}.
\end{equation}
Macierz $W$ w $\Mats{\Hx{A_1} \otimes \Hx{A_2} \otimes \Hx{B_1} \otimes \Hx{B_2}}$ nazywa się \textit{process matrix} (macierzą procesu).
W celu generowania prawidłowego prawdopodobieństwa narzuca się dodatkowe warunki na $W$
\begin{gather}
\label{eq:non_neg}
\WAll \geq 0. \\
\label{eq:sums_to_id1}
\Trs
\left[
\WAll
\left(
M^{A_1A_2} \otimes M^{B_1B_2}
\right)
\right]=1.\\
\label{eq:sums_to_id2}
\forall M^{A_1A_2}, M^{B_1B_2} \geq 0, \Trs_{A_2} \MA = \mathbb{1}^{A_1}, \Trs_{B_2} \MB = \mathbb{1}^{B_1},
\end{gather}
gdzie $\MA = \sum_i \mai{i}$. Warunek \eqref{eq:non_neg} zapewnia, że prawdopodobieństwa nie będą ujemne, a \eqref{eq:sums_to_id1} i  \eqref{eq:sums_to_id2} - pewność zaobserwowania dowolnej pary map. 
%tutej moze macierz gestosci
\begin{figure}[t]
\centering

\begin{tabular}{|c|c|c|c|}
\hline
Przyczynowy porządek & Stany & Kanały & Kanały z pamięcią \\
\hline
$A \npreceq B $ & $A_1, B_1, A_1B_1$ & $A_1B_2$ & $A_1B_1B_2$\\
\hline
$B \npreceq A $ & $A_1, B_1, A_1B_1$ & $A_2B_1$ & $A_1A_2B_1$\\ 
\hline
& \includegraphics[width=0.2\textwidth]{obrazki/states} & \includegraphics[width=0.2\textwidth]{obrazki/channel}& \includegraphics[width=0.2\textwidth]{obrazki/channel_with_memory}\\
\hline
\end{tabular}
\caption{Wyrażenia zgodne z formalizmem i ich proponowana graficzna interpretacja}
\label{fig:configs}
\end{figure}
Baza Hilberta-Schmidta dla $\LHx{X}$ dane jest przez zbiór macierzy $\{\sigma^X_\mu\}^{d^2_X-1}_{\mu=0},$ gdzie $\sigma^X_0 = \mathbb{1}, \Tr{\sigma^X_\mu\sigma^X_\nu}=d_x\delta_{\mu\nu}, \Tr{\sigma^X_{\mu>0}}=0.$ Ogólny element przestrzeni $\Mats{\Hx{A_1}\otimes\Hx{A_2}\otimes\Hx{B_1}\otimes\Hx{B_2}}$ można zapisać, jako
\begin{gather}
\WAll = \sum_{\mu\nu\lambda\gamma}= w_{\mu\nu\lambda\gamma} \sigma_\mu^{A_1}\otimes\sigma_\nu^{A_2}\otimes\sigma_\lambda^{B_1}\otimes\sigma_\gamma^{B_2} \\
w_{\mu\nu\lambda\gamma} \in \mathcal{C} \nonumber.
\end{gather}
Wyrażenia zawierające wyłącznie wyrazy $\sigma^{A_1}_i \otimes \mathbb{1}^{reszta},~(i > 0)$ nazywa się wyrażeniami typu $A_1$, wyrażenia zawierające  $\sigma^{A_1}_i \otimes \sigma^{A_2}_j \otimes \mathbb{1}^{reszta},~(i, j > 0)$ nazywa się wyrażeniami typu $A_1A_2$ etc.
Na rysunku \ref{fig:configs} przedstawiono wyrażenia spełniające \eqref{eq:non_neg} i \eqref{eq:sums_to_id1}. Najogólniejsza macierz procesu zgodna z założeniami to
\begin{gather}
\WAll = \frac{1}{d_{A_1}d_{B_1}}(\mathbb{1} +\sigma^{B \preceq A} + \sigma^{A \preceq B} + \sigma^{A \npreceq \nsucceq B}) \\
\sigma^{A \preceq B} := \sum_{ij>0} a_{ij} \sigma^{A_1}_i \sigma^{B_2}_j + \sum_{ijk>0} b_{ijk} \sigma^{A_1}_i \sigma^{B_1}_j \sigma^{B_2}_k \\
\sigma^{B \preceq A} := \sum_{ij>0} c_{ij} \sigma^{A_2}_i \sigma^{B_1}_j + \sum_{ijk>0} d_{ijk} \sigma^{A_1}_i \sigma^{A_2}_j \sigma^{B_1}_k \\
 \sigma^{A \npreceq \nsucceq B} := \sum_{i>0} e_i  \sigma^{A_1} + \sum_{i>0} f_i  \sigma^{B_1} + \sum_{ij>0} h_{ij} \sigma^{A_1}_i \sigma^{B_1}_j \\
 \forall_{ij} a_{ij}, b_{ij}, c_{ij}, d_{ij}, e_{ij}, f_{ij}, g_{ij}, h_{ij} \in \mathcal{R} \nonumber.
\end{gather}
\section{Przyczynowa separowalność i przyczynowe nierówności}
Macierzami procesu \textit{causally separable} (przyczynowo separowalnymi) nazywa się takie macierze, które można zapisać jako wypukłą kombinację procesów o konkretnym przyczynowym porządku, a mianowicie
\begin{equation}
\label{eq:sep}
\WAll = qW^{B \nprec A} + (1-q)W^{A \nprec B},~0 \leq q \leq 1.
\end{equation}
Powyższa dekompozycja nie musi być jednoznaczna, jako że wyrazy typu $W^{A \nprec \nsucceq B}$ można włączyć do wybranego wyrazu.
Przed wprowadzeniem \textit{causal inequallity} (przyczynowej nierówności) warto wspomnieć o tzw. nierówności Bella. Jest to nieskończona rodzina nierówności, których żaden niesplątany system nie może złamać. Jest to \textit{device independent} (niezależny od implementacji pomiarów) sposób weryfikacji splątania kwantowego.
%%Typowym przykładem jest eksperyment, w którym w środkowym punkcie pomiędzy odległymi laboratoriami
%przygotowuję się dwie cząsteczki i wysyła się po jednej cząstce do każdego z laboratoriów po pierwsza strona, tradycyjnie nazywana Alicją, wykonuje jeden pomiar zwracający jakiś binarny wynik $A_n$ przyjmujący wartości $\pm 1$, następnie wykonuje po raz kolejny pomiar potencjalnie 
%nierówności wynikająca z analizy następującej funkcji zmiennych losowych
%\begin{gather}
%g_n = A_nB_n+ A'_nB_n + A_nB'_n + A'_n+B'_n
%\end{gather}
%\end{multicols*}

Przyjmuje się następujące założenia na temat natury rzeczywistości uporządkowanej przyczynowo:
\begin{description}
	\item[\textit{Causal structure} (Przyczynowa struktura, CS)]
	Wydarzenia obdarzone są częściowym porządkiem w strukturze czasoprzestrzeni, można wyznaczyć kolejność wydarzeń $A \prec B$, która wyznacza kierunek przesyłania informacji; jeżeli $A \prec B$, to możliwe jest sygnalizowanie
	\footnote
	{W przypadku, gdy $A \prec B$ oznacza to, że brzegowy rozkład prawdopodobieństwa otrzymania danego wyniku nie zależy od wejścia drugiej strony. $\Pr(a|x, y) = \Pr(a|x, y')~\forall a,x,y,y'$, $\Pr(a|x,y) = \sum_b \Pr(a,b|x,y)$, gdzie przez a, b oznaczamy wyniki otrzymane przez odpowiednie strony, zaś x, y ich wejścia.} 
	z A do B, lecz nie na odwrót.
	\item[\textit{Free choice} (Wolny wybór, FC)]  
	W przypadku wyboru liczb losowych, możliwe korelacje występują wyłącznie z liczbami z przyszłości.
	\item[\textit{Closed laboratories} (Zamknięte laboratoria, CL)] 
	Liczba odgadnięta przez Alicję może być skorelowana z liczbą losową Boba wyłącznie, jeżeli system wysłany do Alicji jest przed (w sensie przyczynowości) generacją liczby Boba, analogicznie w przypadku odwrotnym.	
\end{description}
Rozważa się następująca dwustronną grę realizowaną wielokrotnie przez dwa odległe laboratoria (Alicję i Boba). W każdej iteracji rozgrywki Alicja i Bob otrzymują na wejściu pewien fizyczny system, wykonują na nim pewne operacje i wysyłają dalej system. Każda ze stron może otrzymać sygnał wyłącznie przez 
system wchodzący do laboratorium, zaś wysłać wyłącznie przez system wychodzący z laboratorium. Widać więc, że jeżeli Alicja otrzyma system, który przeszedł pewną procedurę u Boba, to Bob może wysłać informacje, zaś Alicja może ją wyłącznie odebrać, co uniemożliwia dwustronna sygnalizację.
Każdy z graczy otrzymując system losuje jeden bit wybraną metodą oznaczany a dla Alicji i b dla Boba. Dodatkowo Bob losuje bit b', który decyduje, czy Bob ma zgadywać bit a Alicji, czy Alicja ma zgadywać bit b Boba. Bez utraty ogólności można przyjąć, że obie strony zgadują bit drugiego gracza. W zależności od b' ich 
predykcja może się nie liczyć. Zakłada się, że bity losowane są z równym prawdopodobieństwem. Prawdopodobieństwo sukcesu w takiej grze zapisuje się następująco
\begin{equation}
\Pr{}_{sukcesu} := \frac{1}{2} \left[ \Pr(x=b|b'=0) + \Pr(y=a|b' = 1)\right]
\end{equation}
Każda strategia w uporządkowanej strukturze czasu osiąga $\Pr{}_{sukcesu} \leq \frac{3}{4}$. Optymalna strategie opisuje się nierygorystycznie następująco: w przypadku $A \prec B$ Alicja może zakodować swój bit w pewien sposób w systemie, który wyśle do Boba, dlatego można wybrać taką strategię, że $\Pr(y=a) = 1$, Alicji pozostaje wtedy losowa predykcja co do wartości bitu Boba - $\Pr(x=b) = \frac{1}{2}$. Widać również, że żadna probabilistyczna strategia nie może poprawić wyniku, co daje optymalną strategię. Okazuje się, że korzystając z korelacji opisywanych przez formalizm macierzy procesu $\Pr{}_{sukces} \leq \frac{2+\sqrt{2}}{4}$.
Można rozważyc następującą macierz procesu
\begin{equation}
\WAll = \frac{1}{4}\left[
\I\I\I\I + \frac{1}{\sqrt{2}}(\I\Z\Z\I + q\Z\I\X\Z + \frac{(1-q)}{2}\Z\I\X\I)
\right],~ 0 \leq q \leq 1,
\end{equation}
gdzie, $\X, \Y, \Z$ są macierzami Pauliego, które z $\I$ tworzą bazę Hilberta-Schmidta, zaś w celu skrócenia zapisu pominięto indeks górny, który jest indukowany przez pozycję wyrazu. $\I^{A_1} \otimes \X^{A_2} \otimes \Y^{B_1} \otimes \Z^{B_2} =: \I\X\Y\Z$.
Przedstawioną macierz z $q=1$ wraz z dalej przedstawioną procedurą komunikacji wprowadzono w \cite{process_matrix} jako zasób, który pozwala złamać przyczynową nierówność. W \cite{max_violation} pokazano, że przy odpowiednich założeniach o dozwolonych operacjach jest to maksymalne przekroczenie nierówności
wynikającej z tego zadania. Z drugiej strony widać od razu, że przy $q=0$ mamy $A \prec B$, zatem oczywistym jest, że taki zasób nie pozwala złamać przyczynowej nierówności. Sterując wartością $q$ można zaobserwować odpowiednio przejścia macierzy z ustalonej przyczynowości poprzez separowalną do nieseparowalnej.
Macierze separowalne nie mogą łamać żadnej nierówności przyczynowej, nieseparowalne zostaną dokładniej opisane dalej. Procedura komunikacji wygląda następująco. 
Za każdym razem Alicja mierzy swój system w bazie $z$ i przypisuje $x = 0$ dla $\Ket{z_+}$ zaś $x=1$ dla $\Ket{z_-}$, a następnie przygotowuje na nowo kubit i zakodowuje a w tej samej bazie. Mapa CP odpowiadająca wykryciu stanu $\Ket{\psi}$ i przygotowaniu innego stanu $\Ket{\phi}$ to $\Ket{\psi}\Bra{\psi}^{A_1} \otimes
\Ket{\phi}\Bra{\phi}^A_2$, dlatego mapa CP Alicji wygląda następująco:
\begin{equation}
\xi(x, a) = \frac{1}{4}
\left[
\I + (-1)^x \Z
\right]
\otimes
\left[
\I  + (-1)^a \Z
\right	].
\end{equation}
Natomiast Bob jako posiadacz bitu $b'$, gdy chce odczytać bit Alicji, mierzy przychodzący kubit w bazie $z$i przypisuje wyniki tego pomiaru do y analogicznie jak Alicja. W tym przypadku nieistotne jest jaki stan przygotuje Bob, więc przygotowuje dowolny stan $\rho^{B_2}$ znormalizowany do $\Tr \rho^{B_2} = 1$.
W przypadku $b'=0$, Bob chce wysłać swój bit do Alicji. Dokonuje pomiaru w bazie x, następnie w przypadku wyniku $y = \Ket{x_+}$ zakodowuje swój bit następująco: $0 \to \Ket{z_+}, 1 \to \Ket{z_-}$ w drugim kodowanie wygląda odwrotnie $1 \to \Ket{z_+}, 0 \to \Ket{z_-}$. Jego mapa wygląda następująco
\begin{equation}
\eta(y, b, b') =
\begin{cases}
\frac{1}{2}\left(
\I + (-1)^y\Z
\right) \otimes \rho&b'=1\\
\frac{1}{4} \left[ \I + (-1)^y \X \right] \otimes \left[ \I + (-1)^{b+y} \Z \right]& \text{w przeciwnym wypadku}.
\end{cases}
\end{equation}
Prawdopodobieństwo zaobserwowania danej pary map dane jest następująco:
\begin{equation}
\Pr(x,y|a,b,b') = \Trs\left\{{\WAll\left[\eta(x,a) \otimes \xi(y,b,b') \right]}\right\}
\end{equation}
Przypominając, że prawdopodobieństwo sukcesu w tej grze dane jest jako
\begin{equation}
\Pr{}_{sukcesu} := \frac{1}{2} \left[ \Pr(x=b|b'=0) + \Pr(y=a|b' = 1)\right],
\end{equation}
oblicza się, że
\begin{gather}
\Pr(x=b|b'=0)_q = \frac{\sqrt{2}q+2}{4} \\
\Pr(y=a|b'=1)_q = \frac{\sqrt{2}+2}{4} \\ 
\Pr{}_{sukcesu_q} = \frac{\sqrt{2}q + \sqrt{2} + 4}{8},
\end{gather}
gdzie indeks odnotowuje zależność prawdopodobieństwa od $q$. Tak jak się spodziewano, prawdopodobieństwo sukcesu Alicji rośnie wraz ze zwiększaniem współczynnika przy członie $\Z\I\X\Z$ rozumianym jako reprezentacja kanału kwantowego z pamięcią, który odpowiada za sygnalizujące korelacje $A \preceq B$.
Przy $q = 0$ Alicja ma dostęp wyłącznie do niesygnalizujących nietrywialnych zasobów (wyraz $\Z\I\X\I$), które nie mogą zwiększyć prawdopodobieństwa sukcesu w tej grze, gdyż wymaga ona zasobów sygnalizujących. Argument ten został rygorystycznie pokazany np. w \cite{mp_gyni}. Wraz ze zwiększaniem q Alicja ma dostęp do coraz
większej ilości sygnalizujących zasobów, co pozwala jej częściej wygrywać w owej grze. Ważnym jest zauważyć, że macierz ta jest nieujemna $\WAll \geq 0$ dla $0 \leq q \leq 1$, korzystając z tego protokołu łamie się przyczynową nierówność dla $q \geq \sqrt{2} - 1$, zaś proces jest nieseparowalny dla $q \geq q_0,~q_0 \approx 0.365$.
Separowalność przybliżono numerycznie. Wskazywać to może, że w tej grze i przy wykorzystaniu tej procedury niewystarczającym zasobem do złamania przyczynowych nierówności jest nieseparowalność (w tym przypadku może to być wina nieoptymalnej metody dla danego zasobu), lecz ilustruje fakt, iż niewystarczającym zasobem jest nieseparowalność, co zostanie dalej rygorystycznie pokazane.
\subsection{Procesy z przyczynowym modelem}
Ważną klasę procesów pokazano w \cite{causal_model}. Jest to klasa procesów przyczynowo nieseparowalnych podlegająca przyczynowemu modelowi, czyli takie procesy, które są nieseparowalne, lecz produkują wyłącznie korelacje, które są zgodne z przyczynowym porządkiem. Procesy takie oczywiście nie mogą
łamać przyczynowych nierówności niezależnie od przyjętej strategii. Przykładem takiego procesu jest 
% pozniej opisac przyczynowe polytop %
\begin{gather}
W^{A \prec B} := \IO + \frac{1}{12}(\I\Z\Z\I + \I\X\X\I + \I\Y\Y\I) \\
W^{B \prec A} := \IO + \frac{1}{4}(\Z\I\X\Z)\\
\label{eq:nsep_causal}
W := qW^{A \prec B} + (1-q+\epsilon)W^{B \prec A} -\epsilon\IO,
\end{gather} gdzie $\IO = \frac{1}{d_{A_1}d_{B_1}} \I\I\I\I$.
Zauważa się, że $W \geq 0$ dla $\epsilon \leq q- 1 + \sqrt{\frac{(1-q)(q+3)}{3}}$ i przyczynowo nieseparowalne dla $\epsilon \geq 0$. 
Dowód faktu, że ten proces niemoże złamać żadnej przyczynowej nierówności nie zależnie od strategii przebiega następująco.
Pokazuje się najpierw, że proces ten produkuje te same korelacje co $W^{T_B}$, gdzie $T_B$ oznacza częsciową transpozycje systemów $\Hx{B_1} \otimes \Hx{B_2}$ względem \textit{computational basis} (bazy obliczeniowej). Natomiast $W^{T_B}$ jest przyczynowo separowalna i nie może złamać przyczynowych nierówności. Co razem dowodzi tezę. Pierwsza część dowodu przebiega następująco 
\begin{align}
\begin{split}
\Pr(x,y|a,b) &= \Trs\left[W^{T_B} \xi(x,a) \otimes \eta(y,b)^{T}\right] \\
	&= \sum_{\mu\nu\lambda\gamma} w_{\mu\nu\lambda\gamma} \Trs \left[ (\sigma_\mu^{A_1}\otimes\sigma_\nu^{A_2})\otimes(\sigma_\lambda^{B_1}\otimes\sigma_\gamma^{B_2})^T \xi(x,a) \otimes \eta(y,b)^{T} \right] \\
	&= \sum_{\mu\nu\lambda\gamma} w_{\mu\nu\lambda\gamma} \Trs \left[ (\sigma_\mu^{A_1}\otimes\sigma_\nu^{A_2}) \xi(x,a) \otimes (\sigma_\lambda^{B_1}\otimes\sigma_\gamma^{B_2})^T\eta(y,b)^{T} \right] \\
	&= \sum_{\mu\nu\lambda\gamma} w_{\mu\nu\lambda\gamma}  \Trs \left[ (\sigma_\mu^{A_1}\otimes\sigma_\nu^{A_2}) \xi(x,a)\right] \Trs \left[ (\sigma_\lambda^{B_1}\otimes\sigma_\gamma^{B_2})^T\eta(y,b)^{T} \right] \\
	&= \sum_{\mu\nu\lambda\gamma} w_{\mu\nu\lambda\gamma}  \Trs \left[ (\sigma_\mu^{A_1}\otimes\sigma_\nu^{A_2}) \xi(x,a)\right] \Trs \left[ (\sigma_\lambda^{B_1}\otimes\sigma_\gamma^{B_2})\eta(y,b) \right] \\
	&=  \Trs\left[W \xi(x,a) \otimes \eta(y,b)\right]
\end{split}
\end{align}
Ta równość jest spełniona nawet wtedy, gdy $W^{T_B} \leq 0$, czyli opisuje niefizyczna macierz procesu, taki proces generuje dodatnie prawdopodobieństwo dla lokalnych pomiarów, lecz może generować ujemne prawdopodobieństwa, gdy laboratoria dzielą splątane cząsteczki, takie rozszerzenie jest istotne fizycznie.
%, taka klasa procesów zostanie dalej opisana.
Trzeba zauważyć, że dla każdego kwantowego instrumentu $\{ \eta(y,b) \}$, instrument $\{ \eta(y,b)^T \}$ również jest prawidłowy, jako że transpozycja mapuje mapy CP do map CP i mapy \textit{trace preserving} (TP, zachowujące ślad) do map zachowujących ślad. Następnie pokazuje się w sposób jawny przyczynową
separacje $W^{T_B}$. Widać, że 
\begin{equation}
\left[\IO + \frac{1}{12}\left(\I\Z\Z\I + \I\X\X\I + \I\Y\Y\I\right)\right]^{T_B} = \IO + \frac{1}{12}\I\Z\Z\I + \I\X\X\I - \I\Y\Y\I, 
\end{equation}
po prawej stronie nierówności można rozpoznać macierz procesu opisujący kanał depolaryzacyjny, krótko opisany we wstępie, z prawdopodobieństwem $\frac{2}{3}$ depolaryzacji oraz $\frac{1}{3}$ idealnej transmisji systemu.
Z definicji procesu depolaryzacyjnego pisze się
\begin{align}
D^{A \prec B}_{\frac{2}{3}} &= \frac{2}{3} \IO + \frac{1}{3}I^{A \prec B}  \\
I^{A \prec B} &= \frac{\I\KKet{I}\BBra{I}\I}{2}.
\end{align} Dodając do tego $\left(W^{B \prec A}\right)^{T_B} = W^{B \prec A}$
wynika, że 
\begin{align}
\label{eq:wtb_sep}
\begin{split}
W^{T_B} &= \frac{2q}{3}\IO + \frac{q}{3} I^{A \prec B} + (1-q+\epsilon)W^{B \prec A} - \epsilon \IO \\
 &= \frac{q}{3} I^{A \prec B} + (1-q+\epsilon) W^{B \prec A} - (\frac{2q}{3} - \epsilon) \IO,
\end{split}
\end{align} co jest kombinacją wypukła procesów uporządkowanych przyczynowo tak długo jak $\epsilon < \frac{2q}{3}$ można jednakże sprawdzić, że $q - 1 + \sqrt{\frac{(1-q)(3+q}{3}} \leq \frac{2q}{3}$ więc poprzedni warunek jest zawsze spełniony, co kończy dowód, pokazano, że każdy prawidłowy proces \eqref{eq:nsep_causal} ma przyczynowy model.
%% do poprawy %%
%Autorzy \cite{causal_model} sugerują, że biorąc $W = \left(W^{T_B}\right)^{T_B}$ i korzystając z równania \eqref{eq:wtb_sep} i dodatkowo zauważając, że macierz procesu $\frac{q}{3}\left(I^{A \prec B}\right)^{T_B}$ jest nieujemna, gdy zmiesza się ją z co najmniej $\frac{2q}{3}$
%białego szumu, jednakże ilość białego szumu, który możemy dodać z wyrazu $(\frac{2q}{3} - \epsilon)\IO$ jest ostro mniejsza, niż wymagana, macierz procesu $W$ może być zinterpretowana jako wypukła kombinacja niefizycznego kanału od Alicji do Boba z fizycznym kanałem od Boba do Alicji co jest wskazówką, że
%$W$ jest nieimplementowalne fizycznie.
%% %% %%
Autorzy \cite{causal_mode} sugerują, że biorąc rozkład na kombinacje wypukłe $W$ jako transpozycje względem systemu Boba równania \eqref{eq:wtb_sep}. Można dalej zauważyć, że wyraz $\frac{q}{3} \left( I^{A \prec B} \right)^{T_B}$ stanie się nieujemny, gdy doda się do niego $\frac{2q}{3}$ białego szumu,
a ilość dostępnego szumu, który można zabrać z wyrazu $\left( \frac{2q}{3} - \epsilon \right) \IO$ jest ostro mniejszy od wymaganego. Narzuca się interpretacja, że proces $W$ jest kombinacją wypukła niefizycznego kanału od Alicji do Boba i fizycznego kanału od Boba do Alicji co może być wskazówka, że proces
$W$ jest nieimplementowalny fizycznie.
Powyższy dowód opiera się na fakcie, że mapy poddane częsciowej transpozycji według odpowiedniego systemu są nadal poprawnymi mapami CP.
Może to być jednak nieprawdziwe, gdy systemy są poszerzone o splątane cząsteczki. Częściowa transpozycja nie jest wtedy pełną transpozycją względem danych systemów, czyli może mapować mapy CP na mapy nie CP. Procesy takie, które nie łamią przyczynowych nierówności, a łamią je gdy zostaną rozszerzone o splątany system w odpowiednich laboratoriach nazywa się \textit{not extensibly causal}
o których można przeczytać więcej w \cite{causal_model}.
\section{Świadek przyczynowości} 
Poprzedni rozdział sugeruje, że istnieje klasa procesów, która nie może złamać żadnej przyczynowej nierówności, zaś jest niesparowalna przyczynowo. Istnieje więc motywacja do poszukiwania metody, która sklasyfikuje, czy dany stan jest separowalny czy nie. Wprowadzono w \cite{causal_witness} \textit{causal witness}
(świadek przyczynowości) jest to analog do \textit{entaglement witness} (świadka splątania), który pozwala klasyfikować splątanie danego układu niezależnie od jego zdolności do łamania nierówności Bella. Ściśle mówiąc świadek przyczynowości to taki operator $S$, że
\begin{equation}
\label{eq:witness_gez}
\Trs\left[S W^{sep} \right]\geq 0,
\end{equation}
dla każdego przyczynowo separowalnego procesu $W^{sep}$. Taka definicja jest zmotywowana twierdzeniem o separującej hiperpłaszczyźnie, które mówi, że dla każdych dwóch wypukłych zbiorów albo ich przecięcie nie jest zbiorem pustym, albo istnieje taka hiperpłaszczyzna, że zbiory leża po obu jej stronach, nierygorystycznie mówiąc. Co można łatwo sobie zobrazować geometrycznie. Jako, że zbiory macierzy separowalnych jest wypukły i zamknięte dla każdego nieseparowalnego procesu $W^{nsep}$ istnieje taki świadek przyczynowości, że 
\begin{equation}
\Trs \left[ S_{W^{nsep}} W^{nsep} \right] < 0.
\end{equation}
\subsection{Sformułowanie macierzy procesu niezależne od bazy}
Przed dalszym charakteryzowaniem świadków przyczynowości wygodnie jest wprowadzić niezależne od wyboru bazy sformułowanie macierzy procesu.
Definiuje się następująca operacje
\begin{equation}
{}_X W = \frac{\I^X}{d_X} \otimes \Trs_X W,
\end{equation}
która opisuje operacje wzięcia śladu i zastąpienia tego systemu znormalizowaną macierzą jednostkową.
Warunki wprowadzone w rozdziale \ref{macierz_procesu} są równoważne z następującymi
\begin{gather}
W \geq 0 \\
\Trs W = d_O \\
W = L_V\left(W\right),
\end{gather}
gdzie $d_0 = d_{A_2} d_{B_2} \dots$ jest iloczynem wymiaru wszystkich systemów wyjściowych, a $L_V$ jest projektorem, zdefiniowanym w \cite{causal_witness}, na pewną podprzestrzeń 
$\mathcal{L_V} \subset \Hx{A_1} \otimes \Hx{A_2} \otimes \Hx{B_1} \otimes \Hx{B_2} \dots$.
W sposób jawny projektor dla przypadku dwustronnego $L_V$ wyraża się następująco:
\begin{equation}
\label{eq:projec2}
L_V(W) = {}_{A_2}W + {}_{B_2}W - {}_{A_2B_2}W - {}_{B_1B_2}W + {}_{A_OB_1B_2}W - {}_{A_1A_2}W + {}_{A_1A_2B_2}W.
\end{equation}
Warto tutaj porównać powyższe równanie do poprzedniego sformułowania macierzy procesu. Zauważa się, że w przypadku wybranej bazy Hilberta-Schmidta
operacja
\begin{equation}
{}_X\left[\sigma_\mu^X \otimes \sigma_\nu^Y\right] = \delta_{\mu0}
\end{equation}
Przypomina się, że $\sigma_0 = \I$.
Wynika to oczywiście z faktu, że reszta wyrazów jest bezśladowa i $\frac{\Trs \I^X}{d_X} = 1$. Co daje następującą interpretacje dla wyrazów występujących w \eqref{eq:projec2} są ta wyrazy zakazane w tym formalizmie. Wyrazy, które tu występują odpowiadają sytuacją, które generują niejednostkowe prawdopodobieństwa na poziomie lokalnych pomiarów. np. wyraz typu $A_1A_2$ można interpretować jako pętla czasowa. Ważna jest obserwacja, że posiadając jawną reprezentacje projektora trywialnym zadaniem jest stwierdzić jakie wyrazy z bazy Hilberta-Schmidta są dozwolone - generują prawidłowe prawdopodobieństwa. Jawna postać takiego projektora dla przypadku n stron została wyprowadzona w oryginalnym artykule.
\subsection{Poszukiwanie świadka przyczynowości}
Zauważa się, że warunek \eqref{eq:witness_gez} jest równoważny z następującymi dwoma
\begin{gather}
\label{eq:css2}
\Trs \left[ W^{A \prec B} S\right] \geq 0 \\
\label{eq:css}
\Trs \left[ W^{B \prec A} S\right] \geq 0.
\end{gather}
Co oczywiście wynika z definicji stanów separowalnych, jako kombinacji wypukłej macierzy o określonej przyczynowości.
Łatwo można zaobserwować, że pozbywając się wyrazów zawierających wyrazy typu $\dots B_2$ usuwamy korelacje wyjścia Boba z pomiarami Alicji co
implikuje, że $A \prec B$. Co zapisuje się
\begin{equation}
{}_{B_2} W = W^{A \prec B},
\end{equation}
lub analogicznie
\begin{equation}
{}_{A_2} W = W^{B \prec A}.
\end{equation}
Wykorzystując to, równanie \eqref{eq:css} możemy zapisać następująco
\begin{equation}
\Trs \left[ {}_{A_2} W S\right] \geq 0
\end{equation}
Traktując ślad jako iloczyn skalarny $\langle M S \rangle = \Trs MS$ oraz zauważając, że ${}_X$ jest operatorem samosprzężonym równoważne z powyższym
równaniem jest
\begin{equation}
\Trs \left[ W {}_{A_2}S \right] \geq 0
\end{equation}
Dla prawidłowych macierzy procesu wystarczającym dla $S$ do bycia świadkiem przyczynowości jest 
\begin{gather}
{}_{A_2} S \geq 0 \\
{}_{B_2} S \geq 0.
\end{gather}
Zauważa się dodatkowo dowolność dodania dowolnego elementu $S^\bot$ z przestrzeni ortogonalnej do $\mathcal{L_V}$, który nie zmieni wartości \label{eq:witness_gez}, a mianowicie
\begin{equation}
\Trs\left[W\left(S + S^\bot\right)\right] = \Trs\left[WS\right]
\end{equation}
Okazuje się, że powyższe warunki charakteryzują wszystkich świadków przyczynowości.
Co zbierając razem daje.
\begin{gather}
\text{Macierz hermitowska S jest świadkiem przyczynowości wtedy i tylko wtedy gdy da się ją zapisać, jako} \\
S = S_P + S^\bot \\
\text{gdzie $S_P$ i $S^\bot$ są takimi macierzami hermitowskimi, że} \\ 
{}_{A_2} S_P \geq 0, {}_{B_2} S_P \geq 0, L_V(S^\bot) = 0.
\end{gather}
Pokazuje się, że zbiór tak zdefiniowanych świadków przyczynowości jest domkniętym stożkiem wypukłym. Można jednak, że ograniczyć się z $S$ do przestrzeni 
$\mathcal{L_V}$. Wybierając $S^\bot = L_V(S_P) - S_P$, który może być dowolny. Mamy $L_V(S) = S$. Okazuje się, że taki ograniczony zbiór świadków przyczynowości: $\mathcal{S_V} = \mathcal{S} \cap \mathcal{L_V}$, również jest domkniętym wypukłym stożkiem. Jako, że wybrane elementy ortogonalne do
$\mathcal{L_V}$ nie zmieniają wartości $\Trs WS$ nie zmieniają one też dlatego zdolności S do wykrywania separowalności. 
Dostając pewną macierz $W$ i chcąc zbadać czy jest ona separowalna. Można spróbować znaleźć minimalna wartość $\Trs WS$. W przypadku możliwości 
znalezienia minimum globalnego takiego wyrażenia widzimy, że jeżeli nie uda nam się znaleźć takiego S, że $\Trs WS < 0$ oznacza to, że nie istnieje
taka hiperpłaszczyzna oddzielająca procesy separowalne, więc ten proces też jest separowalny w przeciwnym wypadku proces jest nieseparowalny.
W ograniczenia od dołu skończoną wartością, by możliwe było rozwiązanie problemu numerycznie, $\Trs SW$ należy narzucić pewien dowolny warunek normujący
autorzy oryginalnego artykułu proponują następujący:
\begin{equation}
\Trs \Omega S \leq 1,
\end{equation}
gdzie $\Omega$ jest znormalizowaną macierzą procesu.
Poszerzając powyższy warunek do nieznormalizowanych macierzy procesu, mamy
\begin{equation}
\Trs \Omega S \leq \frac{\Trs \Omega}{d_O}
\end{equation}
Co można przepisać, jako 
\begin{equation}
\Trs \left[ \Omega(\frac{\I}{d_O} -S) \right] \geq 0
\end{equation}
Łatwo zauważyć, że powyższy warunek jest warunkiem, który muszą spełniać operatory $\frac{\I}{d_O} - S,$ by należały do stożka dualnego macierzy procesu, czyli takiego, że ich iloczyn skalarny jest nieujemny z macierzami procesu. Co sprowadza problem optymalizacyjny do:
\begin{gather}
\min \Trs \left[ WS \right]\\
\text{tak, aby } S \in \mathcal{S_V},~ \frac{\I}{d_O} - S \in \mathcal{W^*_V},
\end{gather}
gdzie $\mathcal{W^*_V}:=\mathcal{W^*} \cap \mathcal{L_V}.~ \mathcal{W^*}$ jest wcześniej wspomnianym stożkiem dualnym do macierzy procesu,
zaś człon $\mathcal{L_V}$ wynika z wcześniej narzuconego warunku na $S \in \mathcal{L_V}$. Problem ten okazuje się być prawidłowym problemem
SDP (\textit{semidefinite programming}) - programowaniem liniowym po stożku, którego numeryczne rozwiązanie jest zbieżne do optimum globalnego.
Więc rozwiązanie takiego problemu optymalizacyjnego daje nam kryterium separowalności przyczynowej.
Okazuje się dodatkowo, że wartość $-\Trs \left[ W S^* \right]$ odpowiada minimalnej wartości $\lambda$ takiej, że 
\begin{equation}
\frac{1}{1 + \lambda}\left( W + \lambda\widetilde{\Omega}\right),
\end{equation}
zoptymalizowanej po wszystkich znormalizowanych macierzach procesu $\widetilde{\Omega}$. Wartość ta określa odporność danego procesu do pozostania nieseparowalnym podczas mieszania z "najgorszym" możliwym szumem. $-\Trs \left [ W S^* \right]$ nazywa się, analogicznie do podobnej wartości związanej ze splątaniem, \textit{generalized robustness} (uogólnioną wytrzymałość) oznacza się ją
\begin{equation}
R_g(W) = -\Trs \left[ S^* W \right]
\end{equation} Jest to miara nieseparowalności spełniająca standardowe wymagania, a mianowicie
\begin{description}
\item[Dyskryminacja] $R_g(W) \geq 0$ dla każdej macierzy procesu, przyjmuje wartość 0 wyłącznie dla procesów należących do $\mathcal{W^{sep}}$. 
\item[Wypukłość] $R_g(\sum_i p_i W_i) \leq \sum_i p_i R_g(W_i)$ dla dowolnych macierzy procesu i $p_i \geq 0$ takich, że $\sum_i p_i = 1$. 
\item[Monotoniczność ze względu na lokalne operacje] $R_g\left(\$(W)\right) \leq R_g\left(W\right)$, gdzie $\$(W)$ jest dowolnym procesem, który można 
otrzymać przez złożenie go z lokalnymi mapami CPTP.
\end{description}
Można wprowadzić również problem w którym poszukujemy minimalnej ilości białego szumu potrzebnego do spowodowania, by proces stał się separowalnym, który może się okazać bardziej adekwatnym modelem szumu, niż przypadek pesymistyczny.
Problem optymalizacyjny, który otrzymuje się jest następujący
\begin{gather}
\min \Trs \left[ WS \right]\\
\text{tak, by } S \in \mathcal{S_V}, \Trs\left[\IO S\right] \leq 1.
\end{gather}
Wprowadza się wtedy wielkość nazywaną \textit{random robustness} (losowa wytrzymałość), która jest powiązana z $S^*$ - optimum powyższego problemu - w następujący sposób.
\begin{equation}
R_r(W) = -\Trs\left[S^* W\right]
\end{equation}
W przeciwieństwie do uogólnionej wytrzymałości nie jest to miara nieseparowalności, w sensie poprzednio przytoczonych postulatów, jako że nie jest monotoniczna pod działaniem lokalnych map CPTP.
\subsection{Implementacja świadka przyczynowości}
Korzystając chociażby z twierdzenia spektralnego wiadomym jest, że macierz hermitowską S można zapisać, jako kombinacja liniowa następującej postaci
\begin{equation}
S = \sum_{i,j} \gamma_{i,j} \sigma^{A_1A_2}_i \otimes \sigma^{B_1B_2}_j,
\end{equation} gdzie macierze $\sigma \geq 0$. Dodatkowo w $\gamma_{i,j}$ można dodać stała skalująca tak, aby $\Trs_{A_2} \sigma_i \leq \I^{A_1}$, $\Trs_{B_2} \sigma_j \leq \I^{B_1}$.
Co więcej można dodać do $S$ macierz $\sigma_0^{A_1A_2} \otimes \sigma_0^{B_1B_2}$ o zerowej stałej, która nie zmienia wartości S, tak aby $\sum_i \Trs_{A_2} \sigma^{A_1A_2}_i = \I^{A_1}$ i analogicznie dla strony Boba. Wtedy można traktować macierze $\sigma^{A_1A_2}_i,~ \sigma^{B_1B_2}_j$, jako reprezentacje CJ pewnego instrumentu kwantowego więc wielkość
\begin{equation}
\Trs \left[ W S \right] = \sum_{i,j} \gamma_{i,j} \Trs\left[ W \sigma^{A_1A_2} \otimes \sigma^{B_1B_2} \right],
\end{equation} gdzie wartość po prawej stronie równania jest oczywiście prawdopodobieństwem zaobserwowania danych map, wielkość tą można oszacować eksperymentalnie.
Warto również przypomnieć, że do $S$ można dodać dowolny element z przestrzeni ortogonalnej do przestrzeni $\mathcal{L_V}$, co nie zmienia wartości oczekiwanej świadka, a może skutkować w łatwiejszej do implementacji fizycznie mapie. 
\section{Postulat puryfikacyjny}
Ważnym aktualnie nierozwiązanym problemem występujący w tym formalizmie jest brak jasnego kryterium, które procesy są możliwe do zrealizowania fizycznie.
Nie wiadomo czy łamanie nierówności przyczynowych jest możliwie fizyczne czy wyłącznie jest matematycznym artefaktem. Jasne jednakże jest, że występowanie nieseparowalności jest fizycznie występującym fenomenem, który został potwierdzony doświadczalnie przy realizacji tzw. \textit{quantum switch}
(kwantowego przełącznika) - zasobu który nie może złamać przyczynowych nierówności - wykorzystując wcześniej opisanego świadka przyczynowości np. w \cite{experiment}. Co może nasuwać postulat, że fizycznie niemożliwe jest naruszenie tych nierówności. Prawdziwość tego postulatu wciąż stoi pod znakiem zapytania. W \cite{purification} autorzy proponują \textit{purification postulate} (postulat puryfikacyjny). Uznają za konieczne, że każda fizycznie poprawna teoria
musi być odwracalna. Motywują się faktem, że w każda fundamentalna teoria jest odwracalna i odwracalność była kluczowa w budowaniu teorii kwantowej.
Warto jeszcze dodać, że we wstępie zostały opisany pomiar rzutujący jako nieodwracalny rodzaj ewolucji jednakże można modelować pomiar w sposób niewymagający takich pomiarów modelując układ pomiarowy, jako system kwantowy, który ewoluuje unitarnie wraz z mierzonym systemem co pokazano np. w
\cite{reversible}. W celu dalszego opisu postulatu koniecznym jest opisanie jak rozumiana jest odwracalność w kontekście procesów. W tym celu procesy są poszerzone o globalną przeszłość i globalną przyszłość i rozumie się je jako operacje, która mapuje stany w globalnej przeszłości do stanów w globalnej przyszłości, które przechodzą przez region o nieokreślonej przyczynowości lokalnych laboratoriów opisywanych właśnie przez nie. Co sprowadza do definicji \textit{pure processes} (czystych procesów), jako procesów, które w sposób unitarny transformują przyszłość do przeszłości, gdy w lokalnych laboratoriach zostaną zaaplikowane odpowiednie unitarne transformacje. Ta definicja sprowadza do ich postulatu, który mówi, że procesy są puryfikowalne wtedy i tylko wtedy, gdy da się zaprezentować je jako czyste procesy w większej przestrzeni i tylko takie procesy są implementowalne. Autorzy postulatu dodatkowo zauważają, że
o ile żaden znany dwustronny proces łamiący nierówności przyczynowe okazał się być puryfikowalnym to istnieje proces trzystronny, który jest puryfikowalny i może łamać przyczynowe nierówności, więc jeżeli niemożność łamania przyczynowych nierówności uznałoby się za prawo natury, a ten postulat za prawdziwy to
byłby on konieczny, a nie wystarczający. 
\begin{figure}[t]
\centering
\includegraphics[width=0.6\textwidth]{obrazki/done2}
\caption{
Rysunek symbolizuje działanie procesu $W$, jako funkcje wyższego rzędu map $\mathcal{A}$ i $\mathcal{B}$, która dla danych map zwraca mapę 
$\mathcal{G_{A,B}}$ reprezentująca transformacje, która przechodzi z globalnej przeszłości do globalnej przyszłości.
}
\label{higherordermap}
\end{figure}
W wcześniejszych rozdziałach, proces był definiowany, jako zasób, który definiował wszystkie statystyki pomiarów dla danych instrumentów, lub równoważnie jako funkcja, która mapowała mapy CP do prawdopodobieństw. Wprowadzenie pojęcia puryfikacji wymaga zmienienia definicji na biliniową funkcję działająca trywialnie na \textit{ancille}, która mapuje
$\mathcal{A}$ i $\mathcal{B}$ do $\mathcal{G_{A,B}}$, gdzie $\mathcal{A}$ jest mapą CPTP z $A_1, A'_1$ do $A_2, A'_2$, analogicznie $\mathcal{B}$ jest mapą CPTP z
$B_1, B'_1$ do $B_2, B'_2$, zaś $\mathcal{G_{A,B}}$ mapą CPTP z $P, A'_1, A'_2$ do $F, B'_1, B'_2$. Primem oznaczono \textit{ancille}. Ponownie przez A niepisane kaligraficznie oznaczać będzie się reprezentacje CJ odpowiednich map, podobnie dla innych map. Taka definicja nie jest w żaden sposób sprzeczna z tymi podanymi wcześniej, gdyż ma ona służyć jedynie droga do zbudowania narzędzia stwierdzającego czy dany proces jest fizyczny bądź nie. Trzeba zaznaczyć, iż w tym rozdziale definicja izomorfizmu CJ jest zmieniona o transpozycje, która wcześniej została wprowadzona ze względu na wygodę teraz, jednakże może sprawiać, że pewne mapy CP 
mogą zostać mapowane na macierze niedodatnie. Jako, że żadna przestrzeń nie może sygnalizować P, a przestrzeń F nie może sygnalizować do żadnej innej
można je interpretować odpowiednio, jako globalną przeszłość i globalną przyszłość. Oczywiście tak zdefiniowany proces ma swoją reprezentację jako macierz piszę się
\begin{equation}
\label{eq:longnp}
G_{A,B} = \Trs_{A_1A_2B_1B_2} \left[ W^{T_{A_1A_2B_1B_2}} (A\otimes B)\right]
\end{equation}
gdzie $W \in A_1 \otimes A_2 \otimes A'_1 \otimes A'_2 \otimes B_1 \otimes B_2 \otimes B'_1 \otimes B'_2 \otimes F \otimes P$ jest oczywiście definiowaną macierzą procesu. W powyższym równaniu macierze jednostkowe na \textit{ancillach}, globalnej przyszłości i przeszłości pozostały niejawne.
Rówanie \eqref{eq:longnp} może być skrócone z wykorzystaniem \textit{link product} (iloczynu łączącego).
W celu zapisania postaci CJ złożenia pewnych dwóch funkcji można, by w sposób jawny obliczyć postać CJ $\mathcal{M} \cdot \mathcal{N}$. Wygodniejszym
jednak często okazuje się być wcześniej wspomniany iloczyn łączący definiowany, jako następująca abstrakcyjna operacja na macierzach.
\begin{equation}
N * M = \Trs_{I\cap J}\left[ (\I^{J\setminus I} \otimes M^{T_{I\cap J}})(N \otimes \I^{I\setminus J})\right],
\end{equation}
gdzie $M \in \bigotimes_{i \in I} A^i,~N \in \bigotimes_{j \in J} A^j$. W skrajnych przypadkach gdy $I \cap J = \emptyset$, $N*M$ to po prostu $N \otimes M$, a

gdy $I \cap J = I = J$ to $N * M = \Trs M^T N$.
Znając iloczyn łączący w sposób bardzo elegancki można zdefiniować dwustronny proces jako
\begin{equation}
G_{A,B} = W * (A \otimes B).
\end{equation}
W celu uniknięcia sprzeczności trzeba narzucić warunki na $W$ tak, aby $G_{A,B}$ była mapą odpowiednią CPTP dla wszystkich prawidłowych map CPTP $A$ i $B$. Co implikuje analogiczne warunki do tych podanych w wcześniejszych rozdziałach
\begin{gather}
W \geq 0 \\
\Trs W = d_{A_2}d_{B_2}d_P \\
W = L_V(W).
\end{gather} 
Jawna postać powyższego projektora jest następująca
\begin{align}
\begin{split}
L_V(W) =& W -{}_FW + {}_{A_2F}W + {}_{B_2}W - {}_{A_2B_2F}W\\ &- {}_{A_1A_2F}W + {}_{A_1A_2B_2F}W - {}_{B_1B_2F}W \\&+ {}_{A_2B_1B_2F}W - {}_{A_1A_2B_1B_2F}W + {}_{PA_1A_2B_1B_2F}W.
\end{split}
\end{align}
Ważnym spostrzeżeniem jest fakt, który przekonuje do słuszności poprzedniej definicji macierzy procesu. Definiując $W' = {}_{PF}W$ i korzystając z faktu, że
${}_{XX}W = {}_{X}W$. Po elementarnych przekształceniach wychodzi, że
\begin{equation}
L_V(W') = {}_{A_2}W' + {}_{B_2}W' - {}_{A_2B_2}W' - {}_{B_1B_2}W' + {}_{A_2B_1B_2}W' - {}_{A_1A_2}W' + {}_{A_1A_2B_2}W'.
\end{equation}
Powyższy projektor ma takie same wyrazy, jak ten zdefiniowany w \eqref{eq:projec2} 
Każdy dwustronny proces zdefiniowany w poprzednim sensie rozszerzony o odpowiednio znormalizowaną jednostkową przyszłość i przeszłość spełnia warunki narzucone powyżej. Co pokazuje, że każdy proces dwustronny, definiowany jak poprzednio, jest zgodny z tą definicją.
\subsection{Czysty proces}
Takie sformułowanie daje naturalne sformułowanie co rozumie się przez czysty proces, tak jak transformacje unitarne są najogólniejsza liniowa transformacją, która mapuje pewne czyste stany na inne czyste stany można wprowadzić pojęcie czystych procesów jako takich, które mapują dane mapy unitarne CPTP na inne unitarne mapy CPTP. 
Okazuje się, że macierz procesu $W$ jest czysta wtedy i tylko wtedy, gdy można zapisać $W = \KKet{U_W} \BBra{U_W}$, gdzie $\\Ket{U_W}$ jest reprezentacją wektorową CJ pewnej transformacji unitarnej $U_W$
Dowód powyższego twierdzenia przebiega następująco, jeżeli W jest czystym procesem to z definicji $\mathcal{G_{A,B}}$ jest unitarne. Wybierając $\mathcal{A}$, $\mathcal{B}$, jako operacje SWAP, które odpowiednio zamieniają \textit{ancille} z oryginalnymi systemami to pisze się, że
\begin{equation}
G_{A,B} = W * \left( \KKet{\I}\BBra{\I}^{A'_1 A_2} \KKet{\I}\BBra{\I}^{A_1A'_2} \otimes \KKet{\I}\BBra{\I}^{B'_1 B_2} \KKet{\I}\BBra{\I}^{B_1B'_2}\right) = W,
\end{equation}
gdzie po prawej stronie równania przemiano nazwy odpowiednich przestrzeni. Otrzymuje się z tego, że $G_{A,B} = W = \MCJ (\mathcal{W})$, $\mathcal{W} = \mathcal{G_{A,B}}$, a skoro $\mathcal{G_{A,B}}$ ma być unitarne to oczywiście $\mathcal{W}$ również jest unitarne.
Zapisać można więc, że $\mathcal{W}(\rho) = U_W\rho U_W^\dag$, więc jego reprezentacje CJ rzeczywiście jest opisywana $W = \KKet{U_W}\BBra{U_W}$. W celu pokazania, że powyższa reprezentacja $W$ jest nie tylko konieczna, lecz również wystarczająca, niech
\begin{gather}
W = \KKet{U_W}\BBra{U_W} \\
A = \KKet{U_A}\BBra{U_A} \\
B = \KKet{U_B}\BBra{U_B}
\end{gather}
to
\begin{equation}
G_{A,B} = \KKet{U_W}\BBra{U_W} * \left( \KKet{U_A}\BBra{U_A} \otimes \right) = \KKet{U_G}\BBra{U_G},
\end{equation} gdzie 
\begin{equation}
U_G^{A'_1B'_1P} = \Trs_{A_1B_1} \left[ \left( U_W^{PA_1B_1} \otimes \I^{A'_1B'_1}\right) \left( \I^P \otimes U_A^{A_1A_1'} \otimes U_B^{B_1B'_1}\right)\right]
\end{equation}
Z założenia mamy, że $\mathcal{G_{A,B}}$ jest CPTP więc $\Trs_{A'_2B'_2F} G_{A,B} = \I^{A'_1B'_1P}$. Podstawiając tu $\KKet{U_G}\BBra{U_G}$ dostaje się
\begin{equation}
\Trs_{A'_2B'_2F} \KKet{U_G}\BBra{U_G} = U^\dag_G U_G = \I^{A'_1B'_1P}
\end{equation}
co kończy dowód.
\subsection{Sformułowanie postulatu}
Mając na uwadze wcześniej wprowadzoną definicję czystego procesu można zdefiniować proces puryfikowalny. Jest to taki proces $W$, który można wydobyć
z pewnego czystego procesu $S$ przez wprowadzenie stanu $\Ket{0}^P$ i dokonania operacji częściowego śladu po przyszłości, czyli
\begin{equation}
W = S * \left( \Ket{0}\Bra{0}^P ] \otimes \I^F \right),
\end{equation}
postulowane więc jest, że każdy proces implementowalny fizycznie jest puryfikowalny.
Jest to zmotywowane to faktem, iż gdyby byłoby inaczej 
mapy unitarne byłyby mapowane na mapy, które w ogólności nie muszą być odwracalne co skutkowało by w nieodwracalności tej teorii, a co jest uznawane za ważny element fizycznej rzeczywistości. Warto również zauważyć, że wszystkie procesy o określonej przyczynowości, te które zostały zaimplementowane fizycznie, jak i te separowalne okazują się być puryfikowalne.
\subsection{Warunki konieczne i wystarczające}
Wyprowadzenie koniecznych i wystarczających warunków, by proces wygląda następująco:
Definiując
\begin{equation}
\label{eq:purif}
\Ket{w_\psi}:= \Bra{\psi^*}^P \KKet{U_S}.
\end{equation}
Można zauważyć, że
\begin{equation}
\KKet{U_S} \BBra{U_S} * (\Ket{\psi}\Bra{\psi}^P \otimes \I^F) = \Ket{w_\psi} \Bra{w_\psi} * 1^F = \Trs_F \Ket{w_\psi} \Bra{w_\psi}
\end{equation}
Równanie \eqref{eq:purif} zapisuje się
\begin{equation}
\label{eq:trpurif}
W = \Trs_F \Ket{w_0}\Bra{w_0},
\end{equation}
gdzie $\Ket{w_0}$ oznacza $\Bra{0}^P\KKet{U_S}$.
Wcześniej narzucano, by S mapowało A i B na inną prawidłową mapę CPTP.
Ten warunek można zreformułować w jawny sposób przy pomocy stanów $\Ket{\psi}$.
S jest prawidłowym procesem, kiedy $[ S * (A \otimes B)] * \Ket{\Psi}\Bra{\Psi}^P$ jest prawidłowym stanem kwantowym.
Ważnym jednakże jest zauważyć, że
\begin{equation}
[S * (A \otimes B)] * \Ket{\psi}\Bra{\psi} = (S * \KP \BP^P) * (A \otimes B).
\end{equation}
Warunek, by prawa strona równania produkowała prawidłowe stany dla każdego stanu i każdych dwóch map jest równoważna z warunkiem 
by proces z trywialną przeszłością $(S*\Ket{\psi}\Bra{\psi}^P$ produkował prawidłowe mapy CPTP z trywialną przeszłością z prawidłowych map CPTP.
Zapisując jawnie ten warunek otrzymuje się
\begin{gather}
\forall \Ket{\psi} ~(S * \KP \BP) = \Ket{w_\psi}\Bra{w_\psi} = L_V(\Ket{w_\psi}\Bra{w_\psi}) \nonumber \\
\label{eq:purifproj}
 \Trs \Ket{w_\psi} \Bra{w_\psi} = d_{A_2}d_{B_2}
\end{gather}
gdzie $L_V$ jest poprzednio zdefiniowanym projektorem z $d_P$ = 1.
Równanie \eqref{eq:trpurif} można zidentyfikować jako standardową puryfikacje stanów mieszanych w przestrzeni mniej wymiarowej, jako stanów
czystych w przestrzeniach więcej wymiarowych. Dla macierzy o rozkładzie spektralnym danym
\begin{equation}
W = \sum^{r-1}_i \lambda_i \Ket{\lambda_i}\Bra{\lambda_i},
\end{equation}
gdzie $\lambda_i$ to niezerowe wartości własne, a $\Ket{\lambda_i}$ to odpowiadające im wektory własne.
Poprawną puryfikacją dla takiej macierzy jest
\begin{equation}
\Ket{w_0} = \sum^{r-1}_i \sqrt{\lambda_i} \Ket{\lambda_i} \Ket{i},
\end{equation}
co można łatwo sprawdzić. Puryfikacja ta jest unikatowa z dokładnością do pewnej izometrii V na puryfikowanym systemie, lecz taka izometria nie zmienia
poprawności stanów zwracanych przez proces, więc można ją wybrać jako identyczność bez utraty ogólności, jego przyszłość jako trywialną, więc rozmiar puryfikowanego systemu jako rząd $W$. Pozwala to wybrać $r^2$ wymiarową bazę dla puryfikowanych macierzy. Zapisać wtedy można wektory
$\Ket{w_\psi}$ w tej bazie, jako $\sum^{r-1}_i \alpha_i \Ket{w_i}$. Korzystając teraz z liniowości operacji w warunkach \eqref{eq:purifproj} i cykliczności śladu przepisać je można jako
\begin{gather}
\forall i,j ~L^\perp_V\left(\Ket{w_i}\Bra{w_j}\right) = 0 \nonumber\\
\Bra{w_i}\Ket{w_j} = d_{A_2}d_{B_2}\delta{ij} \\
L^\perp_V = \I - L_V \nonumber,
\end{gather} gdzie $\Ket{w_i} := \Bra{i}^P \KKet{U_S}$.

\subsection{Warunek konieczny}
Okazuje się jednakże, że znalezienie takiego zbioru wektorów $\{ \Ket{v_i} \}$ jest problemem trudnym, gdyż warunek $L^\perp_V(\Ket{v_i}\Bra{v_j})=0$ jest kwadratowy. Dlatego w duchu artykułu, który wprowadził puryfikacje 
zostanie tutaj opisany i wyprowadzony warunek konieczny, który jest łatwy do sprawdzenia. Procesy, które nie spełniają tego warunku będą więc niepuryfikowalne, zaś dla reszty będzie niekonkluzywny. Wektor $\Ket{v_0}$ jest ściśle określony dla danej macierzy, jego postać jest znana więc 
warunek $\LPV(\Ket{v_i}\Bra{v_0}) = 0$ jest liniowy co pozwala scharakteryzować przestrzeń $V_W$ formowaną przez wektory, które je spełniają.
W celu skonstruowania ortonormalnej bazy dla $V_W$ wykorzystuje się $\Pi_\LPV$ zdefiniowany następująco
\begin{equation}
\forall i,j ~\Pi_\LPV \KKet{\Ket{i}\Bra{j}} = \KKet{\LPV(\Ket{i}\Bra{j})}
\end{equation}
Otrzymuje się wtedy, że
\begin{equation}
\LPV(\Ket{v}\Bra{v_0}) = 0 \iff \Pi_\LPV \Ket{v^*_0} \Ket{v} = 0
\end{equation}
Definiując dalej operator $O_W$ dany następująco
\begin{equation}
O_W:= \left(\Bra{w^*_0} \otimes \I\right) \Pi_\LPV \left( \Ket{w^*_0} \otimes \I\right)
\end{equation}
i aplikując go na $\Ket{v}$
\begin{equation}
O_W\Ket{v} = 0 \iff \Pi_\LPV \Ket{w^*_0} \Ket{v} = 0
\end{equation}
Jeżeli $\Ket{v}$ ma spełniać powyższy warunek niezerowe składowe może mieć wyłącznie przy tych wektorach bazowych, które odpowiadają wektorom własnym tego operatora przy których stoją zerowe wartości własne, lub równoważnie wektory własne $O_W$ o zerowych wartościach własnych rozpinają przestrzeń $V_W$. Niech teraz przez $\{ \Ket{r_i}\}$ dane będą właśnie te wektory tworzące ortonormalna bazę w $V_W$ oraz definiując $R = \sum_i \Ket{i}\Bra{r_i}$. Ograniczyć można ten projektor to przestrzeni $V^*_W \otimes V_W$ w następujący sposób
\begin{equation}
\Pi_{\LPV|V_W} = \left(R^* \otimes R \right) \Pi_\LPV \left(R^{*\dag} \otimes R^\dag \right)
\end{equation}
Niech teraz $\{ \Ket{m_k} \}^{d_m-1}_k=0$ będzie zbiorem wektorów własnych $\Pi_{\LPV|V_W}$ z niezerową wartością własną. Korzystając z argumentu analogicznego do tego powyżej 
\begin{equation}
\Pi_{\LPV|V_W} \Ket{v^*_j}\Ket{v_i} = 0 \iff \forall k \Bra{v^*_j} \Bra{v_i} \Ket{m_k} = 0
\end{equation}
Można teraz spostrzec, że można przepisać powyższy warunek w sposób wygodniejszy na
\begin{equation}
\Bra{v^*_j} \Bra{v_i} \Ket{m_k} = \Bra{v_i} M_k \Ket{v_j}
\KKet{M_k} = \Ket{m_k}.
\end{equation}
W ogólności macierze $M_k$ nie są hermitwoskie, a konieczne są rzeczywiste wartości własne w celu skorzystania z twierdzenia, które zaraz zostanie przytoczone.
Definiuje się
\begin{gather}
C_k = M_k + M^\dag_k
C_{k+d_m} = i(M_k - M_k^\dag)
\end{gather}
Widać oczywiście, że $\frac{C_k-iC_{k+d_m}}{2} = M_k$, a same macierze $C_k$ zostały zdefiniowane jako hermitowskie. Daje to możliwość zapisania, że
\begin{equation}
\Pi_{\LPV|V_W} \Ket{v^*_j}\Ket{v_i} = 0 \iff \forall k \Bra{v_i} C_k \Ket{v_j}
\end{equation}
Dalsze rozwijanie i badanie tego warunku wystarczającego jest otwarty problemem. Udowodniono jednak w opisywanym artykule, że
rozmiar przestrzeni, której wektory spełniają
\begin{equation}
\Bra{v}C_k\Ket{v} = 0
\end{equation} równy jest 
\begin{equation}
d_{C_k} = n_{k0} + \min({n_{k+}, n_{k-}}),
\end{equation} gdzie $n_0, n_k+, n_k-$ są odpowiednio liczbą zerowych, dodatnich i ujemnych wartości własnych k-tej macierzy. Intuicyjne uzasadnienie tego twierdzenia może być następujące: dostępnych jest $n_0$ składowych, które nie wpływają na ten wynik oraz $\min({n_{k+}, n_{k-}}$, które trzeba wyzerować odpowiednio drugim znakiem, wybierając znak, którego jest więcej zabrakłoby po prostu składowych do ich wyzerowania.
Więc prostym ograniczeniem, które okazuje się być w wielu przypadkach nietrywialne jest wzięcie rozmiaru najmniejszej przestrzeni, jeżeli będzie ona mniejsza niż rząd $W$ to macierz będzie niepuryfikowalna, lub zwięźle
\begin{gather}
\text{W jest puryfikowalne} \implies d_{max}(W) \geq \Rank(W) \\
d_{max}(W) := \min_i d_{C_i} 
\end{gather}
\section{Przykłady}
W rozdziale trzecim podano przykład procesu, które może łamać przyczynowe nierówności. Okazuje się, że ten proces nie jest puryfikowalny dla skrajnego q = 1, puryfikowalny dla q=0 jest puryfikowalny bo przyczynowy, zaś ze względu na złożoność obliczeniową i brak dostępnych wyników w literaturze nie wiadome jest dla jakich q ten proces jest puryfikowalny.

Kolejnymi interesującymi przykładami są kanały kwantowe. Wektor procesu dla kanału kwantowego jest następująco:
\begin{equation}
\Ket{w_{channel}}^{A \prec B} = \KKet{\I}^{PA_1}\KKet{\I}^{A_2B_1}\KKet{\I}^{B_2F}.
\end{equation}
Reprezentuje on oczywiście zasób, które ma ściśle określoną przyczynowość, dlatego nie może złamać żadnych nierówności przyczynowych.
Biorąc proces następujący
\begin{equation}
a\Ket{w_{channel}}\Bra{w_{channel}}^{A \prec B} + b\Ket{w_{channel}}\Bra{w_{channel}}^{B \prec A},
\end{equation} warunek normujący daje, że $a+b=1$, więc ewidentnie proces jest separowalny. Co za tym idzie on również nie może złamać nierówności przyczynowych. Taki zasób można interpretować jako probabilistyczny kanał, który z pewnym prawdopodobieństwem decyduje, kto jest przed kim.
Eksplorując dalej procesy związane w prosty sposób z kanałami można zadać sobie pytanie co w takim razie dzieje się z dajmy na to "koherentnie" zmieszanym kanałem, niech wektor procesu będzie dany
\begin{equation}
\Ket{w_{procesu}} = a\Ket{w_{channel}}^{A \prec B} + b\Ket{w_{channel}}^{B \prec A}
\end{equation}
Okazuje się jednakże, że niestety proces dany tym wektorem nie należy do przestrzeni poprawnych procesów, gdy dwa współczynniki są różne od zera. W celu uratowanie tego wybornego pomysłu spróbowano wziąć 
\begin{equation}
W' = CL_V(W).
\end{equation}
$C$ jest stałą normalizacyjną równą $\frac{1}{4\Trs W'}$.
W celu złamania nierówności danej w trzecim rozdziale wykorzystano następujący protokół. Gdyby dany był idealny dwustronny kanał można by otrzymać system w jednym laboratorium zmierzyć $\Ket{i}\Bra{i}$ i powiązać przesyłany bit z odebranym stanem, przypisać odpowiednio swój bit do stanu i wysłać go do drugiego laboratorium. Idąc za pomysłem, że proces powyższy reprezentuje pewnego rodzaju pozostałość z takiego idealnego dwustronnego kanału przyjmuje się właśnie tą procedurę. Odpowiednie mapy są więc dane
\begin{gather}
\eta(x,a) = \Ket{x}\Bra{x} \otimes \Ket{a}\Bra{a} \\
\xi(y,b,b') = \eta(y,b)
\end{gather}
Przypomina się, że prawdopodobieństwo jest dane jak zwyczaj, czyli
\begin{equation}
\Pr(x,y|a,b,b`) = \Trs\left\{{\WAll\left[\eta(x,a) \otimes \xi(y,b,b') \right]}\right\}
\end{equation}
Okazuje się, że prawdopodobieństwo sukcesu w grze zdefiniowanej w rozdziale trzecim wynosi $0.8$ dla $a=b$, który wydaję się być maksymalnym połączeniem dwóch kanałów.
Niestety radości musi ukrócić fakt, że powyższa macierz okazuje się nie być nieujemna. Dodając najmniejszą ilość białego szumu takiego, że $W'$ będzie nieujemne czyli
\begin{equation}
W'' = W' + \lambda_{min} \I,
\end{equation} gdzie $\lambda_{min}$ to najmniejsza wartość własna.
Otrzymuje się prawdopodobieństwo równe około $0.68$. Co niestety ujmuje przydatności i wyjątkowości takiego zasobu. Co niestety zmusza do szukania innych ciekawych implementowalnych fizycznie procesów.
W celu spelnienia warunku normalizacyjnego $a + b \leq C$, gdzie C jest pewną stałą, dlatego bez utraty ogólności można wybierać $a + b = 1$ i następnie dokonywać procesu renormalizacji. Na rysunku \ref{fig:bichannel} pokazano prawdopodobieństwo sukcesu dla rodziny procesów generowanych powyżej opisaną metodą.
\begin{figure}[th]
\centering

\includegraphics[width=0.5\textwidth]{obrazki/probchannel.png}
\caption{Wykres pokazujący zależność między a a prawdopodobieństwem sukcesu}
\label{fig:bichannel}
\end{figure}

Bardzo ważnym przykładem, który został zaimplementowany fizycznie, który potwierdza występowanie w fizyce nieprzyczynowego porządku jest \textit{quantum switch}. Jest to proces, w którym kanały kwantowe są w superpozycji zależnej od stanów w przeszłości. Jego wektor wygląda następująco
\begin{equation}
\Ket{w_{switch}} = \Ket{0}^{P_1}\KKet{\I}^{P_2A_1}\KKet{\I}^{A_2B_1}\KKet{\I}^{B_2F_2}\Ket{0}^{F_1}+\Ket{1}^{P_1}\KKet{\I}^{P_2B_1}\KKet{\I}^{B_2A_1}\KKet{\I}^{A_2F_2}\Ket{1}^{F_1},
\end{equation} gdzie $F = F_1 \otimes F_2$, $P = P_1 \otimes P_2$. Proces ten jest ewidentnie reprezentacją wektorową CJ pewnego unitarnego operatora. Wystarczy zobaczyć, że lewy wyraz można zapisać jako
\begin{equation}
\sum_{i,j,k} \Ket{0} \Ket{i,j,k}\Ket{i,j,k}\Ket{0},
\end{equation} powyżej pominięto nazwy odpowiednich systemów i wybrano odpowiednią kolejność.
Macierz, która ma taką postać CJ to
\begin{equation}
\sum_{i,j,k} \Ket{0} \Ket{i,j,k}\Bra{i,j,k}\Bra{0},
\end{equation} która widocznie przyjmuje postać macierzy diagonalem postaci $diag(1,0,1,0,1,0,...)$, niezależnie od kolejności wybranych systemów tak długo jak odpowiednie wyrazy są w różnym bra i kecie. Analogicznie można pokazać, że drugi wyraz ma postać $diag(0,1,0,1...)$ - uzupełnia do jedynki. Jako, że izomorfizm CJ jest liniowy a wyrazy mieszane w iloczynie $U^\dag U$ nie będą występować ze względu na postać wyrazów to pokazuje, że powyższy zasób jest unitarny. Kubit kontrolny z $P_1$ pozostaje niezmieniony zaś badając zmianę stanu z $P_2$ można dowiedzieć się, jaką "drogę" przebyły. Taki zasób nie jest w stanie złamać żadnych nierówności przyczynowych.
Nie jest żaden znany puryfikowalny przykład w literaturze, który byłby w stanie złamać przyczynowe nierówności, jednakże znany jest proces trzystronny, wprowadzony w \cite{logic}, który jest w stanie złamać przyczynowe nierówności. 
\begin{equation}
W_{det} = \sum_{a,b,c} \Ket{a,b,c}\Bra{a,b,c} \otimes \Ket{\neg b \land c, \neg c\land a \neg a\land b} \Bra{\neg b \land c, \neg c\land a ,\neg a\land b},
\end{equation} systemy zostały zapisane w następującej kolejności $A_2B_2C_2A_1B_1C_1$. Korzystając ze standardowej metody zamieniania nieodwracalnych logicznych funkcji w odwracalne pisze się zamienia się
$\Ket{x} \mapsto \Ket{f(x)}$ na $\Ket{x}\Ket{y} \mapsto \Ket{x}\Ket{y \oplus f(x)}$ wykorzystując to powyższy proces można przepisać w postaci wektorowej na
\begin{equation}
\Ket{w} = \sum_{a,b,c,e,f,g} \Ket{a,b,c}\Ket{e,f,g} \otimes \Ket{a,b,c}\Ket{i \oplus \neg b \land c,f \oplus \neg c\land, a , g\oplus \neg a\land b},
\end{equation} gdzie systemy zostały wypisane w kolejności $A_2B_2C_2PFA_1B_1C_1$. Tutaj zarówno przeszłość jak i przyszłość mają po trzy kubity. Co stanowi puryfikacje powyższego procesu.
\section{Wnioski}
W pracy przedstawiono podstawy formalizmu macierzy procesu. Zaprezentowano przykładowe zadanie, w który nieprzeczynowe zasoby mogę osiągać lepsze wyniki, niż zasoby o określonym porządku przyczynowym. Następnie pokazano narzędzie, które zostało wykorzystane do eksperymentalnego potwierdzenia
braku ścisłego określenia przyczynowości w przyrodzie. Opisano następnie proponowany postulat, który miałby określać czy dany proces jest implementowalny fizycznie. Podano parę oryginalnych przykładów. Poszukiwanie wektorów, które spełniałyby warunek wystarczający i konieczny okazuje się być trudnym problemem, więc zademonstrowano wyprowadzenie 
warunku koniecznego, który sprowadza się do działań algebry liniowej. Badanie nieprzyczynowości wydaje się być popularnym nurtem w informatyce kwantowej, który niesie wiele nadziei na nowe ważne odkrycia,chociażby na połączenie mechaniki kwantowej z grawitacją. Istnieje wiele elementów, które wymagają rozwinięcia.
Ewidentnym brakiem w prezentowanym na końcu postulacie jest brak jakichkolwiek innych przesłanek na jego słuszność, niż intuicja fizyczna. Wymagana jest w celu utwardzenie słuszności powyższego postulat wiele eksperymentów fizycznych, jednakże ze względu na pewien metafizyczny charakter tego postulatu będzie to trudne.
Ważne są również badania nad skutecznymi metodami spełniania wystarczającego warunku, gdyż problematyczne będą procesy niewykluczane przez warunek konieczny.


\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
%\listoftables

\bibliographystyle{plain}
\bibliography{bibliografia}

\end{document}
